{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8df78ab-8ca9-42f3-b367-5a6365689d99",
   "metadata": {},
   "source": [
    "# Labeled text sentiment\n",
    "\n",
    "For the python-based packages: Stanza and Pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4118f17-aace-43e5-81ea-0f6a6ac3303c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b417d0b1-6935-46c7-802a-9b6895756a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1499 entries, 0 to 1498\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               1499 non-null   object\n",
      " 1   aspect             1387 non-null   object\n",
      " 2   overall-sentiment  1493 non-null   object\n",
      " 3   aspect1-sentiment  1386 non-null   object\n",
      " 4   aspect2-sentiment  556 non-null    object\n",
      " 5   aspect3-sentiment  207 non-null    object\n",
      " 6   aspect4-sentiment  96 non-null     object\n",
      " 7   aspect5-sentiment  45 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 93.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1493 entries, 0 to 1498\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               1493 non-null   object\n",
      " 1   aspect             1382 non-null   object\n",
      " 2   overall-sentiment  1493 non-null   object\n",
      " 3   aspect1-sentiment  1381 non-null   object\n",
      " 4   aspect2-sentiment  552 non-null    object\n",
      " 5   aspect3-sentiment  205 non-null    object\n",
      " 6   aspect4-sentiment  95 non-null     object\n",
      " 7   aspect5-sentiment  45 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 105.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data-raw/sentence-labels.csv\")\n",
    "df.info()\n",
    "# Remove rows missing overall sentiment\n",
    "df.dropna(subset = ['overall-sentiment'], inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902e835-1dbf-4feb-867a-d0a2197ede63",
   "metadata": {},
   "source": [
    "## Count keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51cf13b-5f80-4b88-b6a9-2daa99824331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nkw_df = pd.read_excel('data-raw/Keywords for lexicon-based sentiment classifier.xlsx',\\n                      sheet_name = 'Word Delineations')\\n\\n#neg_keywords=pd.read_csv('data-raw/negative_keywords.csv').iloc[::,0]\\nneg_keywords = kw_df['Negative '].dropna().str.strip().str.lower().tolist()\\n\\nprint(type(neg_keywords))\\nprint(neg_keywords[:5])\\n\\n#pos_keywords=pd.read_csv('data-raw/positive_keywords.csv').iloc[::,0]\\npos_keywords = kw_df['Positive '].dropna().str.strip().str.lower().tolist()\\nprint(pos_keywords[:5])\\n\\nkw = {'pos': pos_keywords,\\n      'neg': neg_keywords,\\n      'all': neg_keywords + pos_keywords}\\n\\n# We need to have the longer phrases first to ensure that nested keywords\\n# are not detected multiple times. Sort by descending word count.\\nkw['all'].sort(key = lambda x: len(x.split()), reverse = True)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use next code block.\n",
    "\"\"\"\n",
    "kw_df = pd.read_excel('data-raw/Keywords for lexicon-based sentiment classifier.xlsx',\n",
    "                      sheet_name = 'Word Delineations')\n",
    "\n",
    "#neg_keywords=pd.read_csv('data-raw/negative_keywords.csv').iloc[::,0]\n",
    "neg_keywords = kw_df['Negative '].dropna().str.strip().str.lower().tolist()\n",
    "\n",
    "print(type(neg_keywords))\n",
    "print(neg_keywords[:5])\n",
    "\n",
    "#pos_keywords=pd.read_csv('data-raw/positive_keywords.csv').iloc[::,0]\n",
    "pos_keywords = kw_df['Positive '].dropna().str.strip().str.lower().tolist()\n",
    "print(pos_keywords[:5])\n",
    "\n",
    "kw = {'pos': pos_keywords,\n",
    "      'neg': neg_keywords,\n",
    "      'all': neg_keywords + pos_keywords}\n",
    "\n",
    "# We need to have the longer phrases first to ensure that nested keywords\n",
    "# are not detected multiple times. Sort by descending word count.\n",
    "kw['all'].sort(key = lambda x: len(x.split()), reverse = True)\n",
    "\"\"\"\n",
    "#keywords['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6d2034-9a28-4bc2-baea-e3fd4d2827ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does not enjoy',\n",
       " 'does not want',\n",
       " 'not a candidate',\n",
       " 'not well controlled',\n",
       " 'not well treated']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load keywords and combine pos+neg keywords together \n",
    "# \"\"\"\n",
    "all_keywords=[]\n",
    "# Files are downloaded from https://drive.google.com/drive/u/0/folders/1ZdED366Wa2Hrbd2VSz7zbvRJ2iJZ1S81\n",
    "# Dated November 29, 2020\n",
    "neg_keywords=pd.read_csv('data-raw/negative_keywords.csv').iloc[::,0].dropna().str.strip().str.lower().tolist()\n",
    "pos_keywords=pd.read_csv('data-raw/positive_keywords.csv').iloc[::,0].dropna().str.strip().str.lower().tolist()\n",
    "\n",
    "all_keywords.append(neg_keywords)\n",
    "all_keywords.append(pos_keywords)\n",
    "\n",
    "keywords=[i.lower() for i in all_keywords for i in i]\n",
    "keywords.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "kw = {'pos': pos_keywords,\n",
    "      'neg': neg_keywords,\n",
    "      'all': neg_keywords + pos_keywords}\n",
    "\n",
    "# We need to have the longer phrases first to ensure that nested keywords\n",
    "# are not detected multiple times. Sort by descending word count.\n",
    "kw['all'].sort(key = lambda x: len(x.split()), reverse = True)\n",
    "kw['all'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f6d7fc-c6a0-461d-85e6-242026e7e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Copied from MIMIC_003_keyword_labelling.ipynb\n",
    "def find_keywords_final(text, keywords = kw['all']):\n",
    "    found_keywords=[]\n",
    "    text=str(text).lower()\n",
    "    for i in keywords: \n",
    "        if re.search(r'\\b{}\\b'.format(i), text): \n",
    "            if i not in ' '.join(found_keywords):\n",
    "                found_keywords.append(i)\n",
    "    return [text, found_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd135d8f-b4ef-40c2-b289-021db80ff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d12d6b-f3c7-4dc3-867a-47d1e92997e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keywords import find_keywords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c5802f-7b9e-4a53-8178-61296d49f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 3.2 ms, total: 4.47 s\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['find_keywords'] = df.text.apply(find_keywords2, keywords = kw['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28471461-e458-4924-9160-789589681100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         {'distress': [(2068, 2075)]}\n",
       "1    {'concerning': [(265, 274)], 'distress': [(243...\n",
       "2                           {'outpatient': [(36, 45)]}\n",
       "3                              {'concern': [(46, 52)]}\n",
       "4                            {'unclear': [(566, 572)]}\n",
       "Name: find_keywords, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['find_keywords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "564d2727-2321-4846-adf6-6037cf1099e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword_counts'] = df.find_keywords.apply(lambda x: { key: len(values) for key, values in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113bcdb6-1fa3-411a-9fa6-2e23f9a41324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     {'distress': 1}\n",
       "1    {'concerning': 1, 'distress': 1}\n",
       "2                   {'outpatient': 1}\n",
       "3                      {'concern': 1}\n",
       "4                      {'unclear': 1}\n",
       "Name: keyword_counts, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be0cd3e-2872-42ed-885c-b9a8980f52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand each keyword count into its own column.\n",
    "df2 = pd.DataFrame(df['keyword_counts'].tolist(), index=df.index).fillna(0).astype(np.int8)\n",
    "# Sort alphabetically\n",
    "df2 = df2[sorted(df2.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f4f5cc-f985-4b2c-9b6a-8a4a2ef4e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advocate</th>\n",
       "      <th>agreeable</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>appropriately</th>\n",
       "      <th>bad</th>\n",
       "      <th>better</th>\n",
       "      <th>catastrophic</th>\n",
       "      <th>challenging</th>\n",
       "      <th>comfortable</th>\n",
       "      <th>compensated</th>\n",
       "      <th>...</th>\n",
       "      <th>uneventful</th>\n",
       "      <th>unfortunate</th>\n",
       "      <th>unknown</th>\n",
       "      <th>unstable</th>\n",
       "      <th>well controlled</th>\n",
       "      <th>worrisome</th>\n",
       "      <th>worse</th>\n",
       "      <th>worsening</th>\n",
       "      <th>would not want</th>\n",
       "      <th>would want</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   advocate  agreeable  appropriate  appropriately  bad  better  catastrophic  \\\n",
       "0         0          0            0              0    0       0             0   \n",
       "1         0          0            0              0    0       0             0   \n",
       "2         0          0            0              0    0       0             0   \n",
       "3         0          0            0              0    0       0             0   \n",
       "4         0          0            0              0    0       0             0   \n",
       "\n",
       "   challenging  comfortable  compensated  ...  uneventful  unfortunate  \\\n",
       "0            0            0            0  ...           0            0   \n",
       "1            0            0            0  ...           0            0   \n",
       "2            0            0            0  ...           0            0   \n",
       "3            0            0            0  ...           0            0   \n",
       "4            0            0            0  ...           0            0   \n",
       "\n",
       "   unknown  unstable  well controlled  worrisome  worse  worsening  \\\n",
       "0        0         0                0          0      0          0   \n",
       "1        0         0                0          0      0          0   \n",
       "2        0         0                0          0      0          0   \n",
       "3        0         0                0          0      0          0   \n",
       "4        0         0                0          0      0          0   \n",
       "\n",
       "   would not want  would want  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()\n",
    "#df2.info()\n",
    "#df2.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608e7980-3c8c-417b-8da8-4e25613a2a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct positive keywords found (37): well controlled, successful, resolution, unconcerned, would want, advocate, not concerned, low risk, good, outpatient, improving, straightforward, appropriately, great, stability, uneventful, resolved, reasonable, encouraged, compensated, encouraging, excellent, improved, optimized, treated, pleasant, stable, properly, comfortable, controlled, prefers, appropriate, improvement, better, routine, preferable, agreeable \n",
      "\n",
      "Distinct negative keywords found (47): bad, worrisome, inoperable, challenging, not improving, unfortunate, failed, unstable, no improvement, labile, concerning, frail, unable, decompensated, grave, poor, declining, difficult, distress, unclear, in distress, not controlled, worsening, does not want, uncontrolled, would not want, severe, instability, not treated, high risk, futile, unknown, catastrophic, grim, concerned, concern, despite, not resolved, not well controlled, poorly controlled, maximum, worse, refractory, not able, not a candidate, getting worse, not appropriate\n"
     ]
    }
   ],
   "source": [
    "cols_pos = set(df2.columns).intersection(kw['pos'])\n",
    "cols_neg = set(df2.columns).intersection(kw['neg'])\n",
    "\n",
    "print(f\"Distinct positive keywords found ({len(cols_pos)}):\", \", \".join(cols_pos), \"\\n\")\n",
    "print(f\"Distinct negative keywords found ({len(cols_neg)}):\",  \", \".join(cols_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4256dfa-4955-4589-abc2-52c4a6b85b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.idxmax()\n",
    "#df2.loc[1039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cda9f524-8699-41e9-b2f8-cc0900580e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row sums for the positive keywords\n",
    "df['keyword_count_pos'] = df2[cols_pos].sum(axis = 1)\n",
    "df['keyword_count_neg'] = df2[cols_neg].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "203dbf3f-b1c4-45c4-aca9-6ffd8b87d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1493 entries, 0 to 1498\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               1493 non-null   object\n",
      " 1   aspect             1382 non-null   object\n",
      " 2   overall-sentiment  1493 non-null   object\n",
      " 3   aspect1-sentiment  1381 non-null   object\n",
      " 4   aspect2-sentiment  552 non-null    object\n",
      " 5   aspect3-sentiment  205 non-null    object\n",
      " 6   aspect4-sentiment  95 non-null     object\n",
      " 7   aspect5-sentiment  45 non-null     object\n",
      " 8   find_keywords      1493 non-null   object\n",
      " 9   keyword_counts     1493 non-null   object\n",
      " 10  keyword_count_pos  1493 non-null   int64 \n",
      " 11  keyword_count_neg  1493 non-null   int64 \n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 151.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19693539-471e-4f2b-9e76-adb24f46d970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1493 entries, 0 to 1498\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               1493 non-null   object\n",
      " 1   aspect             1382 non-null   object\n",
      " 2   overall-sentiment  1493 non-null   object\n",
      " 3   aspect1-sentiment  1381 non-null   object\n",
      " 4   aspect2-sentiment  552 non-null    object\n",
      " 5   aspect3-sentiment  205 non-null    object\n",
      " 6   aspect4-sentiment  95 non-null     object\n",
      " 7   aspect5-sentiment  45 non-null     object\n",
      " 8   find_keywords      1493 non-null   object\n",
      " 9   keyword_counts     1493 non-null   object\n",
      " 10  keyword_count_pos  1493 non-null   int64 \n",
      " 11  keyword_count_neg  1493 non-null   int64 \n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 151.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca19ec5-972e-4017-99d3-84cef5cc12ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_count_pos</th>\n",
       "      <th>keyword_count_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.620898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.833059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword_count_pos  keyword_count_neg\n",
       "count        1493.000000        1493.000000\n",
       "mean            0.710650           0.620898\n",
       "std             0.809213           0.833059\n",
       "min             0.000000           0.000000\n",
       "25%             0.000000           0.000000\n",
       "50%             1.000000           0.000000\n",
       "75%             1.000000           1.000000\n",
       "max            10.000000          11.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['keyword_count_pos', 'keyword_count_neg']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64a997d6-adf2-4a2c-845e-9580529f0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cbind df2 onto df\n",
    "df = pd.concat([df, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60df1f32-9d52-426c-974f-df800485c861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1493 entries, 0 to 1498\n",
      "Data columns (total 96 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   text                 1493 non-null   object\n",
      " 1   aspect               1382 non-null   object\n",
      " 2   overall-sentiment    1493 non-null   object\n",
      " 3   aspect1-sentiment    1381 non-null   object\n",
      " 4   aspect2-sentiment    552 non-null    object\n",
      " 5   aspect3-sentiment    205 non-null    object\n",
      " 6   aspect4-sentiment    95 non-null     object\n",
      " 7   aspect5-sentiment    45 non-null     object\n",
      " 8   find_keywords        1493 non-null   object\n",
      " 9   keyword_counts       1493 non-null   object\n",
      " 10  keyword_count_pos    1493 non-null   int64 \n",
      " 11  keyword_count_neg    1493 non-null   int64 \n",
      " 12  advocate             1493 non-null   int8  \n",
      " 13  agreeable            1493 non-null   int8  \n",
      " 14  appropriate          1493 non-null   int8  \n",
      " 15  appropriately        1493 non-null   int8  \n",
      " 16  bad                  1493 non-null   int8  \n",
      " 17  better               1493 non-null   int8  \n",
      " 18  catastrophic         1493 non-null   int8  \n",
      " 19  challenging          1493 non-null   int8  \n",
      " 20  comfortable          1493 non-null   int8  \n",
      " 21  compensated          1493 non-null   int8  \n",
      " 22  concern              1493 non-null   int8  \n",
      " 23  concerned            1493 non-null   int8  \n",
      " 24  concerning           1493 non-null   int8  \n",
      " 25  controlled           1493 non-null   int8  \n",
      " 26  declining            1493 non-null   int8  \n",
      " 27  decompensated        1493 non-null   int8  \n",
      " 28  despite              1493 non-null   int8  \n",
      " 29  difficult            1493 non-null   int8  \n",
      " 30  distress             1493 non-null   int8  \n",
      " 31  does not want        1493 non-null   int8  \n",
      " 32  encouraged           1493 non-null   int8  \n",
      " 33  encouraging          1493 non-null   int8  \n",
      " 34  excellent            1493 non-null   int8  \n",
      " 35  failed               1493 non-null   int8  \n",
      " 36  frail                1493 non-null   int8  \n",
      " 37  futile               1493 non-null   int8  \n",
      " 38  getting worse        1493 non-null   int8  \n",
      " 39  good                 1493 non-null   int8  \n",
      " 40  grave                1493 non-null   int8  \n",
      " 41  great                1493 non-null   int8  \n",
      " 42  grim                 1493 non-null   int8  \n",
      " 43  high risk            1493 non-null   int8  \n",
      " 44  improved             1493 non-null   int8  \n",
      " 45  improvement          1493 non-null   int8  \n",
      " 46  improving            1493 non-null   int8  \n",
      " 47  in distress          1493 non-null   int8  \n",
      " 48  inoperable           1493 non-null   int8  \n",
      " 49  instability          1493 non-null   int8  \n",
      " 50  labile               1493 non-null   int8  \n",
      " 51  low risk             1493 non-null   int8  \n",
      " 52  maximum              1493 non-null   int8  \n",
      " 53  no improvement       1493 non-null   int8  \n",
      " 54  not a candidate      1493 non-null   int8  \n",
      " 55  not able             1493 non-null   int8  \n",
      " 56  not appropriate      1493 non-null   int8  \n",
      " 57  not concerned        1493 non-null   int8  \n",
      " 58  not controlled       1493 non-null   int8  \n",
      " 59  not improving        1493 non-null   int8  \n",
      " 60  not resolved         1493 non-null   int8  \n",
      " 61  not treated          1493 non-null   int8  \n",
      " 62  not well controlled  1493 non-null   int8  \n",
      " 63  optimized            1493 non-null   int8  \n",
      " 64  outpatient           1493 non-null   int8  \n",
      " 65  pleasant             1493 non-null   int8  \n",
      " 66  poor                 1493 non-null   int8  \n",
      " 67  poorly controlled    1493 non-null   int8  \n",
      " 68  preferable           1493 non-null   int8  \n",
      " 69  prefers              1493 non-null   int8  \n",
      " 70  properly             1493 non-null   int8  \n",
      " 71  reasonable           1493 non-null   int8  \n",
      " 72  refractory           1493 non-null   int8  \n",
      " 73  resolution           1493 non-null   int8  \n",
      " 74  resolved             1493 non-null   int8  \n",
      " 75  routine              1493 non-null   int8  \n",
      " 76  severe               1493 non-null   int8  \n",
      " 77  stability            1493 non-null   int8  \n",
      " 78  stable               1493 non-null   int8  \n",
      " 79  straightforward      1493 non-null   int8  \n",
      " 80  successful           1493 non-null   int8  \n",
      " 81  treated              1493 non-null   int8  \n",
      " 82  unable               1493 non-null   int8  \n",
      " 83  unclear              1493 non-null   int8  \n",
      " 84  unconcerned          1493 non-null   int8  \n",
      " 85  uncontrolled         1493 non-null   int8  \n",
      " 86  uneventful           1493 non-null   int8  \n",
      " 87  unfortunate          1493 non-null   int8  \n",
      " 88  unknown              1493 non-null   int8  \n",
      " 89  unstable             1493 non-null   int8  \n",
      " 90  well controlled      1493 non-null   int8  \n",
      " 91  worrisome            1493 non-null   int8  \n",
      " 92  worse                1493 non-null   int8  \n",
      " 93  worsening            1493 non-null   int8  \n",
      " 94  would not want       1493 non-null   int8  \n",
      " 95  would want           1493 non-null   int8  \n",
      "dtypes: int64(2), int8(84), object(10)\n",
      "memory usage: 274.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b97689-c98b-4ca2-96a2-e21b05c1626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this code is extracted from MIMIC_003_keyword_labelling.ipynb\n",
    "# We are running this for comparison to the above keyword counts.\n",
    "\n",
    "#kw_df.head()\n",
    "all_patients = df\n",
    "\n",
    "#Create new column of TEXT that is split per sentence \n",
    "all_patients['TEXT_SPLIT']=all_patients.text.map(lambda x: x.split('. '))\n",
    "\n",
    "all_patients['FOUND_KEYWORDS']=all_patients.TEXT_SPLIT.map(lambda x: find_keywords_final(x)[1])\n",
    "\n",
    "#all_patients.FOUND_KEYWORDS.map(lambda x: ', '.join(x)) \n",
    "\n",
    "negative_keywords=[i.strip().lower() for i in neg_keywords]\n",
    "positive_keywords=[i.strip().lower() for i in pos_keywords]\n",
    "\n",
    "#all_patients['AGGR_KEYWORDS']=all_patients.FOUND_KEYWORDS.map(lambda x: [a for a in x for a in a])\n",
    "\n",
    "all_patients['NUM_POS_KEYWORDS']=all_patients.FOUND_KEYWORDS.map(lambda x: len([i for i in x if i in positive_keywords]))\n",
    "all_patients['NUM_NEG_KEYWORDS']=all_patients.FOUND_KEYWORDS.map(lambda x: len([i for i in x if i in negative_keywords]))\n",
    "\n",
    "all_patients['FOUND_STRING_KEYWORDS']=all_patients.FOUND_KEYWORDS.map(lambda x: ', '.join(x)) \n",
    "#final_df=pd.concat([all_patients.drop('AGGR_STRING_KEYWORDS',axis=1), all_patients['AGGR_STRING_KEYWORDS'].str.get_dummies(sep=', ')], axis=1)\n",
    "\n",
    "# CK: Skip this, we already have the keyword counts.\n",
    "#Final_df adds columns where each keyword is a dummy variable \n",
    "#final_df=pd.concat([all_patients.drop('FOUND_STRING_KEYWORDS',axis=1), all_patients['FOUND_STRING_KEYWORDS'].str.get_dummies(sep=', ')], axis=1)\n",
    "#final_df.head(5)\n",
    "\n",
    "# df = final_df\n",
    "\n",
    "df = all_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8953a6-95b1-4b5d-9d0a-048eccd75787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1715147b-bc73-4c17-9af3-776328325c9a",
   "metadata": {},
   "source": [
    "## Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78baf800-baec-4e10-a94a-8de336a6e558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa158095c5d46ddb1ec82e7cc164773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:31:44 INFO: Downloading default packages for language: en (English)...\n",
      "2022-02-25 05:31:45 INFO: File exists: /home/ck37/stanza_resources/en/default.zip.\n",
      "2022-02-25 05:31:48 INFO: Finished downloading models and saved to /home/ck37/stanza_resources.\n",
      "2022-02-25 05:31:48 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2022-02-25 05:31:48 INFO: Use device: gpu\n",
      "2022-02-25 05:31:48 INFO: Loading: tokenize\n",
      "2022-02-25 05:31:51 INFO: Loading: sentiment\n",
      "2022-02-25 05:31:51 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')       # This downloads the English models for the neural pipeline\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a047ff6c-7b91-49fa-8951-22e56a9b6b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 120 ms, total: 24.3 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This takes 1-2 minutes\n",
    "\n",
    "overall_sent = []\n",
    "for text in df.text.values:\n",
    "#    print(text)\n",
    "    doc = nlp(text)\n",
    "    sentiments = []\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sentiments.append(sentence.sentiment)\n",
    "    overall_sent.append(np.mean(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ddbb9c4-86bf-4d97-af69-b4ac0eca2027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 2.0, 0.0, 0.6666666666666666]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34886d05-8fa8-4132-9cb2-0557c3e5c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stanza_sent'] = overall_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37595e65-8b36-4439-b18b-94da307ee4b3",
   "metadata": {},
   "source": [
    "## Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b90bc474-a569-483c-ac6c-9712111e3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 76.2 ms, total: 2.29 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pattern.en import sentiment\n",
    "sent_results = df.text.apply(lambda x: sentiment(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "088c032b-1ce6-4394-942b-d58111898525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pattern_sent'] = sent_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "225ba739-5e5b-490d-ada7-749a5cbbdb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_count_pos</th>\n",
       "      <th>keyword_count_neg</th>\n",
       "      <th>advocate</th>\n",
       "      <th>agreeable</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>appropriately</th>\n",
       "      <th>bad</th>\n",
       "      <th>better</th>\n",
       "      <th>catastrophic</th>\n",
       "      <th>challenging</th>\n",
       "      <th>...</th>\n",
       "      <th>well controlled</th>\n",
       "      <th>worrisome</th>\n",
       "      <th>worse</th>\n",
       "      <th>worsening</th>\n",
       "      <th>would not want</th>\n",
       "      <th>would want</th>\n",
       "      <th>NUM_POS_KEYWORDS</th>\n",
       "      <th>NUM_NEG_KEYWORDS</th>\n",
       "      <th>stanza_sent</th>\n",
       "      <th>pattern_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.00000</td>\n",
       "      <td>1493.00000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.00000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.00000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.00000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.620898</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.033490</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016075</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.042867</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.575352</td>\n",
       "      <td>0.330730</td>\n",
       "      <td>0.025301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.833059</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>0.147068</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>0.179972</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.02588</td>\n",
       "      <td>0.099763</td>\n",
       "      <td>0.218538</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.681276</td>\n",
       "      <td>0.663473</td>\n",
       "      <td>0.638265</td>\n",
       "      <td>0.223917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword_count_pos  keyword_count_neg    advocate   agreeable  \\\n",
       "count        1493.000000        1493.000000  1493.00000  1493.00000   \n",
       "mean            0.710650           0.620898     0.00067     0.00067   \n",
       "std             0.809213           0.833059     0.02588     0.02588   \n",
       "min             0.000000           0.000000     0.00000     0.00000   \n",
       "25%             0.000000           0.000000     0.00000     0.00000   \n",
       "50%             1.000000           0.000000     0.00000     0.00000   \n",
       "75%             1.000000           1.000000     0.00000     0.00000   \n",
       "max            10.000000          11.000000     1.00000     1.00000   \n",
       "\n",
       "       appropriate  appropriately         bad       better  catastrophic  \\\n",
       "count  1493.000000    1493.000000  1493.00000  1493.000000    1493.00000   \n",
       "mean      0.022103       0.004019     0.00067     0.033490       0.00067   \n",
       "std       0.147068       0.073115     0.02588     0.179972       0.02588   \n",
       "min       0.000000       0.000000     0.00000     0.000000       0.00000   \n",
       "25%       0.000000       0.000000     0.00000     0.000000       0.00000   \n",
       "50%       0.000000       0.000000     0.00000     0.000000       0.00000   \n",
       "75%       0.000000       0.000000     0.00000     0.000000       0.00000   \n",
       "max       1.000000       2.000000     1.00000     1.000000       1.00000   \n",
       "\n",
       "       challenging  ...  well controlled   worrisome        worse  \\\n",
       "count  1493.000000  ...      1493.000000  1493.00000  1493.000000   \n",
       "mean      0.002009  ...         0.016075     0.00067     0.010047   \n",
       "std       0.044796  ...         0.125806     0.02588     0.099763   \n",
       "min       0.000000  ...         0.000000     0.00000     0.000000   \n",
       "25%       0.000000  ...         0.000000     0.00000     0.000000   \n",
       "50%       0.000000  ...         0.000000     0.00000     0.000000   \n",
       "75%       0.000000  ...         0.000000     0.00000     0.000000   \n",
       "max       1.000000  ...         1.000000     1.00000     1.000000   \n",
       "\n",
       "         worsening  would not want   would want  NUM_POS_KEYWORDS  \\\n",
       "count  1493.000000     1493.000000  1493.000000       1493.000000   \n",
       "mean      0.042867        0.004019     0.004019          0.673141   \n",
       "std       0.218538        0.063287     0.063287          0.681276   \n",
       "min       0.000000        0.000000     0.000000          0.000000   \n",
       "25%       0.000000        0.000000     0.000000          0.000000   \n",
       "50%       0.000000        0.000000     0.000000          1.000000   \n",
       "75%       0.000000        0.000000     0.000000          1.000000   \n",
       "max       3.000000        1.000000     1.000000          5.000000   \n",
       "\n",
       "       NUM_NEG_KEYWORDS  stanza_sent  pattern_sent  \n",
       "count       1493.000000  1493.000000   1493.000000  \n",
       "mean           0.575352     0.330730      0.025301  \n",
       "std            0.663473     0.638265      0.223917  \n",
       "min            0.000000     0.000000     -0.700000  \n",
       "25%            0.000000     0.000000     -0.053125  \n",
       "50%            0.000000     0.000000      0.000000  \n",
       "75%            1.000000     0.333333      0.069444  \n",
       "max            5.000000     2.000000      1.000000  \n",
       "\n",
       "[8 rows x 90 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42de44-7545-49b7-9c7d-23f3e337f8ec",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5453a565-e23d-4893-820c-6ed461f4280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data/labels-python-predicted-sentiment.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70353060-ad23-4cd2-9ac5-6c96da325d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clinical-sentiment]",
   "language": "python",
   "name": "conda-env-clinical-sentiment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
