---
title: "Analysis"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(rio)
library(ggplot2)
library(flextable)
```

## Import data 

```{r import_data}
# Generated by Catherine from a jupyter notebook.
# data = rio::import("data/keyword_prevalence_per_patient.csv")
# 41k unique patients.
# length(unique(data$SUBJECT_ID))

data = rio::import("data/keyword_prevalence_per_patient_10.12.csv")
#data = arrow::read_feather("data/keyword_prevalence_per_patient_10.12.feather")
dim(data)
# Only 7.7k patients.
length(unique(data$SUBJECT_ID))
names(data) = tolower(names(data))
names(data)

str(data)

# Originally each keyword was only an indicator, not a set of counts :/
# Updated version now shows that it is count.
data %>%
  select(advocate:`wouldn't want`) %>%
  #select(able:`wouldn't want`) %>%
  summarize(across(.fns = max))

# TODO: sort in descending order and create a plot.
```
### Remove age < 18

```{r remove_under_18}
data = data %>% filter(age >= 18)
dim(data)
```

### Merge other sentiment measures

```{r merge_sentiment}
# Created by sentences-to-sentiment.Rmd
df2 = rio::import("data/notes-sentiment.feather")
dim(df2)
names(df2)
dim(data)
# No missing values.
colMeans(is.na(df2))

# Created by 02_notes-to-sentences.ipynb
# note_df = arrow::read_feather("data/02-notes-to-sentences-prep.feather")
# Why is cgid missing for 33% of the rows, shouldn't it have full coverage?
# colMeans(is.na(note_df[, c("row_id", "cgid")]))

head(df2)

names(data)

# Row id is a unique ID in chart events.
df = dplyr::left_join(data, df2, by = "row_id")
# Make sure that we didn't add any extra rows during the join.
stopifnot(nrow(df) == nrow(data))

tail(names(df), 10)
names(df2)
# 0% missingness - phew.
colMeans(is.na(df[, setdiff(names(df2), "row_id")]))

df %>% select(any_of(setdiff(names(df2), "row_id"))) %>%
  is.na() %>% colMeans()

table(df$category, useNA = "ifany")

str(df2)

 
df$miss_merge = as.integer(is.na(df$sentences))
mean(df$miss_merge)

# Now use this updated dataframe.
data = df
rm(df)
gc()
```

## EDA statistics

Used in the abstract

```{r eda}
# Percentage of notes with any sentiment keywords
mean(data$num_neg_keywords > 0 | data$num_pos_keywords > 0)

median(data$num_neg_keywords)
median(data$num_pos_keywords)

table(data$category)

data$cat = factor(data$category)
table(data$cat)
levels(data$cat)
#levels(data$cat)[2] = "Discharge"
levels(data$cat)[6] = "Rehab"
data$cat = forcats::fct_infreq(data$cat)

data$total_sentiment_terms = data$num_neg_keywords + data$num_pos_keywords

# Median sentiment terms per category.
tapply(data$total_sentiment_terms, data$category, median)
```

## Sentiment terms

### Patient visits with sentiment

```{r patient_sent}
# What percentage of patient visits have:
# Any sentiment
# Any positive sentiment
# Any negative sentiment
part1 = data %>% group_by(subject_id, hadm_id) %>%
  # Without "keep" it will claim to only group results by subject_id,
  # However it  only means that each group has a single result row.
  summarize(.groups = "keep",
            notes_with_positive = sum(num_pos_keywords > 0),
            notes_with_negative = sum(num_neg_keywords > 0),
            notes_with_any = sum(num_pos_keywords > 0 | num_neg_keywords > 0))
dim(part1)

part1 %>%
  ungroup() %>%
  summarize(pct_visits_with_any_pos = mean(notes_with_positive > 0),
            pct_visits_with_any_neg = mean(notes_with_negative > 0),
            pct_visits_with_any_sent = mean(notes_with_positive > 0 | notes_with_negative > 0))

# Again, excluding discharge summaries this time.
part1 = data %>% group_by(subject_id, hadm_id) %>%
  # Could be drop or keep here, this does not really impact the results.
  summarize(.groups = "drop",
            notes_with_positive =
              sum(ifelse(cat == "Discharge", NA, num_pos_keywords > 0), na.rm = TRUE),
            notes_with_negative =
              sum(ifelse(cat == "Discharge", NA, num_neg_keywords > 0), na.rm = TRUE),
            notes_with_any =
              sum(ifelse(cat == "Discharge", NA, num_pos_keywords > 0 | num_neg_keywords > 0), na.rm = TRUE))
# Double-check that row count is normal - check.
dim(part1)  
names(part1)

part1 %>%
  ungroup() %>%
  summarize(pct_visits_with_any_pos = mean(notes_with_positive > 0),
            pct_visits_with_any_neg = mean(notes_with_negative > 0),
            pct_visits_with_any_sent = mean(notes_with_positive > 0 | notes_with_negative > 0))
```

### Patient visit note categories

How many notes does the average patient have in each category?

```{r patient_note_cats}
table(data$cat)
part1 = data %>% group_by(subject_id, hadm_id) %>%
  summarize(num_discharge = sum(cat == "Discharge"),
            num_nursing = sum(cat == "Nursing"),
            num_phys = sum(cat == "Physician"),
            num_resp = sum(cat == "Respiratory"),
            num_gen = sum(cat == "General"),
            num_nutr = sum(cat == "Nutrition"),
            num_rehab = sum(cat == "Rehab"),
            num_consult = sum(cat == "Consult"))
dim(part1)

# Generate summary statistics for each note type.
cats_short = c("discharge", "nursing", "phys", "resp", "gen", "nutr", "rehab", "consult")
stats = lapply(cats_short,
       function(cat) {
         var_name = paste0("num_", cat)
         list(median = median(part1[[var_name]]),
              max = max(part1[[var_name]]),
              #min = min(part1[[var_name]]),
              mean = mean(part1[[var_name]]),
              any = mean(part1[[var_name]] > 0))
       })

(stats_df = cbind(category = cats_short, data.table::rbindlist(stats)))
data.table::setDF(stats_df)

ft = stats_df
ft$mean = scales::number(ft$mean, accuracy = 0.01)
ft$any = scales::percent(ft$any, accuracy = 0.1)
ft$category = stringr::str_to_sentence(ft$category)
names(ft) = stringr::str_to_sentence(names(ft))
ft

ft = flextable(ft) %>%
  bold(part = "header")
save_as_docx(ft, path = "tables/patient-note-distribution.docx")  

```

### Any sentiment in note category

```{r any_sentiment_cat}
(sent_tab = data %>% group_by(category) %>%
  summarize(obs = n(),
            pct_with_any_pos = mean(num_pos_keywords > 0),
            pct_with_any_neg = mean(num_neg_keywords > 0),
            pct_with_any_sent = mean(num_pos_keywords > 0 | num_neg_keywords > 0)) %>%
  arrange(desc(obs)) %>%
  mutate(across(c(pct_with_any_pos, pct_with_any_neg, pct_with_any_sent), scales::percent, accuracy = 0.1),
         obs = scales::comma(obs)))

library(flextable)
(ft = flextable(sent_tab) %>%
  set_header_labels(
    category = "Note category",
    obs = "Notes",
    pct_with_any_pos = "Detected\npositive\nsentiment",
    pct_with_any_neg = "Detected\nnegative\nsentiment",
    pct_with_any_sent = "Detected\nany\nsentiment") %>%
  bold(part = "header") %>%
    align(align = "center", part = "all") %>%
    align(j = "obs", align = "right", part = "body"))# %>%
    #autofit())
save_as_docx(ft, path = "tables/sentiment-prevalence-by-category.docx")

```

### Sentiment counts

```{r plots}

# Histogram of sentiment count by category.
(p = ggplot(data, aes(x = total_sentiment_terms)) +
  geom_histogram(fill = "white", color = "black") + 
  theme_minimal() + 
  labs(x = "Sentiment terms in note", y = "Count of notes") +
  lims(x = c(0, 50)) +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1))  +
  facet_grid(cat ~ ., scales = "free") + 
  theme(panel.spacing = unit(1, "lines")))
ggsave("visuals/category-sentiment.png",
       width = 5, height = 7, dpi = 300)

# Not working great compared to default ggplot
# library(ragg)
# ggsave("visuals/category-sentiment.png",
#        width = 500, height = 800, limitsize = FALSE,
#        #width = 5, height = 8,
#        device = ragg::agg_png, res = 300)
# 
# agg_png("visuals/category-sentiment.png", width = 500, height = 800, res = 144)
# p
# dev.off()

library(tidyr)

head(names(data), 20)

# Make a long format plot_df with separate rows for positive and negative counts.
plot_df = tidyr::pivot_longer(data[, c("subject_id", "hadm_id", "cat", "charttime", "num_pos_keywords", "num_neg_keywords", "cgid")],
                              c("num_pos_keywords", "num_neg_keywords"),
                              names_to = "sentiment_type", values_to = "count")

head(plot_df, 20)

plot_df$sentiment_type = factor(plot_df$sentiment_type)
levels(plot_df$sentiment_type) = c("Negative keywords", "Positive keywords")


data.table::setDT(plot_df)
plot_df[, y_max := sum(count == 0), by = .(cat, sentiment_type)]

table(plot_df$y_max)
plot_df[, y_max := max(y_max), by = cat]
table(plot_df$y_max)

library(hrbrthemes)

library(facetscales)

table(data$cat)

scales_y <- list(
  Nursing = scale_y_continuous(limits = c(0, 32000)),
  Discharge = scale_y_continuous(limits = c(0, 32000)),
  Physician = scale_y_continuous(limits = c(0, 32000)),
  Respiratory = scale_y_continuous(limits = c(0, 32000)),
  General = scale_y_continuous(limits = c(0, 32000)),
  Nutrition = scale_y_continuous(limits = c(0, 32000)),
  Rehab = scale_y_continuous(limits = c(0, 32000)),
  Consult = scale_y_continuous(limits = c(0, 32000))
)

# Show positive and negative sentiment by category.
ggplot(plot_df, aes(x = count, fill = sentiment_type)) +
  geom_histogram(alpha = 0.4, color = "#c0c0c0", position = "identity") + 
  theme_ipsum_rc(base_size = 8, plot_margin = margin(4, 4, 4, 4)) +
  #theme_minimal(base_family = "Roboto Condensed") +
  labs(x = "Sentiment terms in note", y = "Count of notes") +
  scale_y_comma() + #expand = expansion(mult = c(0, 0.05))) +
  #scale_y_continuous(labels = scales::comma_format(accuracy = 1),
                     #limits = c(0, y_max)) +
 #                    NULL) +
                    # limits = c(0, 32000))  +
  lims(x = c(0, 30)) +
  #scale_fill_ipsum() + 
  theme(#legend.position = c(0.8, 0.4),
        legend.position = "top",
        #legend.text = element_text(size = 7),
        legend.background = element_rect(fill = "#f3f3f3", color = "#e5e5e5"),
        #legend.margin = margin(l = 3, b = 2, r = 2),
        legend.margin = margin(l = 2, b = 2, r = 2, t = 2),
        legend.box.margin = margin(),
        legend.key.size = unit(0.7, "line"),
        panel.background = element_rect(color = "#c5c5c5"),
        panel.grid.minor.y = element_blank(),
        legend.title = element_blank()) +
  #facet_grid(cat ~ ., scales = "free") +
  facet_wrap(vars(cat), ncol = 3L, scales = "free_y") +
  #facetscales::facet_grid_sc(vars(cat), scales = scales_y) +
  #geom_blank(aes(y = y_max)) + 
  theme(panel.spacing = unit(0.6, "lines"))

ggsave("visuals/category-sentiment-pos-neg.png",
       #width = 5, height = 7, dpi = 300)
       width = 5, height = 5, dpi = 300)

```

## Length of stay

```{r los}
table(data$length_of_stay)
head(data$length_of_stay)
los = data$length_of_stay
data$length_of_stay = as.integer(gsub("^(\\d+) days$", "\\1", data$length_of_stay))
summary(data$length_of_stay)
qplot(data$length_of_stay)
sum(data$length_of_stay <= 30)

data$admittime = lubridate::ymd_hms(data$admittime)
head(data$admittime)
data$dischtime = lubridate::ymd_hms(data$dischtime)
head(data$dischtime)

# Create a new length of stay outcome variable, which will be in hours.
data$los2 = as.numeric(data$dischtime - data$admittime, "hours")
class(data$los2)
summary(data$los2)

# Set negative values to missing.
data$los2[data$los2 < 0] = NA
table(is.na(data$los2))
summary(data$los2)

# Compare to the existing version.
head(data[, c("length_of_stay", "los2")])

data$los_days = as.numeric(data$dischtime - data$admittime, "days")
# Set negative values to missing.
data$los_days[data$los_days < 0] = NA
summary(data$los_days)
qplot(data$los_days)
#qplot(data$los_days, data$length_of_stay) + theme_minimal()

# Correlation of 99.98% - seems reasonable.
cor(data$los_days, data$length_of_stay, use = "pairwise.complete.obs")

# Compare to the existing version.
head(data[, c("length_of_stay", "los2", "los_days")])
```

## Note dates

```{r note_dates}
# TODO: need Catherine to include chartdate in addition to charttime.

#head(data[, c("charttime", "chartdate")])
head(data[, c("charttime")])
# 28% of notes have no chart time, and chart date is missing.
data$charttime = lubridate::ymd_hms(data$charttime)

mean(is.na(data$charttime)) # 28% missing.

# Review missingness by note type.
# They're all discharge summaries.
table(data$category, is.na(data$charttime))

head(data[, c("charttime")])

head(data$charttime - data$admittime)

# This time difference will be in minutes, so convert to hours.
data$note_hours_since_admit = as.numeric(data$charttime - data$admittime, "hours")
head(data$note_hours_since_admit)
```

## Sentiment exposures (note level)

```{r note_sentiment}
# Key count difference
data$sent_pos_minus_neg = data$num_pos_keywords - data$num_neg_keywords
summary(data$sent_pos_minus_neg)
qplot(data$sent_pos_minus_neg) + theme_minimal()

# Proportion of positive sentiment
data$sent_pct_pos = data$num_pos_keywords / (data$num_pos_keywords + data$num_neg_keywords)
summary(data$sent_pct_pos)
data$sent_pct_neg = data$num_neg_keywords / (data$num_pos_keywords + data$num_neg_keywords)

qplot(data$sent_pct_pos) + theme_minimal() + 
  labs(x = "Percentage of positive sentiment",
       y = "Notes") +
  scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +
  scale_x_continuous(labels = scales::percent_format())
ggsave("visuals/sentiment-pct-positive.png",
       width = 5, height = 5)
```


## Generate sentiment trajectory

```{r sent_trajectory}
traj_df =
  data %>% group_by(subject_id, hadm_id) %>%
    # Subset to patients with length of stay greater than 3 days
    filter(los_days > 3)  %>%
    # Subset to notes from the first 72 hours.
    filter(note_hours_since_admit < 72) %>%
    # Subset to visits with at least 3 notes - drops some visits 
    filter(n() >= 3)

#names(traj_df)

# 62k notes
dim(traj_df)
# Only 5,513 patients.
length(unique(traj_df$subject_id))
# 6,391 visits.
length(unique(traj_df$hadm_id))

# Average of 9.7 notes per admission.
nrow(traj_df) / length(unique(traj_df$hadm_id))


# Pick 10 random patients and show their trajectories.
set.seed(1)

deceased_ids = unique(traj_df$hadm_id[traj_df$expire_flag == TRUE])
alive_ids = unique(traj_df$hadm_id[traj_df$expire_flag == FALSE])

selected_deceased = sample(deceased_ids, 6L)
selected_alive = sample(alive_ids, 6L)

(selected_admissions = sample(unique(traj_df$hadm_id), 15L))
plot_df = rbind(traj_df[traj_df$hadm_id %in% selected_alive, ],
                traj_df[traj_df$hadm_id %in% selected_deceased, ]) %>%
  arrange(expire_flag, hadm_id)

# Confirm that the stacked datasets worked well:
plot_df %>% group_by(hadm_id) %>% filter(row_number() == 1) %>% select(hadm_id, expire_flag)

  #group_by(hadm_id) %>%
  #mutate(visit_label = group_indices(.))

#rank(unique(plot_df$hadm_id))
#rank(plot_df$hadm_id)
#plot_df$visit_label = rank(plot_df$hadm_id)

# Convert to a factor so that the sorted order is enforced for the plot.
plot_df$hadm_id = factor(plot_df$hadm_id,
                         levels = as.character(unique(plot_df$hadm_id)))
class(plot_df$hadm_id)
levels(plot_df$hadm_id)


patient_plot = function(lm = FALSE) {
  
  if (lm) {
    smooth_method = "lm"
    y_limits = c(0, 1)
  } else {
    #smooth_method = "loess"
    smooth_method = stats::loess
    # Doesn't work:
    #smooth_method = stats::lowess
    #smooth_method = mgcv::gam
    y_limits = c(-0.1, 1.17)
  }

  ggplot(plot_df,
       aes(x = note_hours_since_admit,
           y = sent_pct_neg)) +
  theme_minimal() +
  # We change geom_smooth() to geom_line() in order for alpha to work.
  geom_line(mapping = aes(colour = sent_pct_neg),
            se = FALSE,
            alpha = 0.3,
            show.legend = FALSE,
            method = smooth_method,
            stat = "smooth",
            size = 0.8) + #, color = "blue") +
  geom_point(aes(color = sent_pct_pos), show.legend = FALSE) +
  scale_color_gradient(low = "red", high = "blue") +
  scale_y_continuous(labels = scales::percent_format(),
                     limits = y_limits,
                     breaks = c(0, 0.5, 1)) + 
  scale_x_continuous(breaks = seq(0, 72, by = 24)) + 
  theme(panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.background = element_rect(color = "#e0e0e0")) +
  labs(x = "Hours since admission",
       y = "Percentage of negative sentiment") +
  #facet_grid(hadm_id ~ .)
  facet_wrap(vars(hadm_id), nrow = 2) + 
  coord_cartesian(clip = "off") +
  theme(panel.spacing = unit(1, "lines"),
        #strip.text.y = element_blank())
        strip.text.y = element_text(size = 6))

}

patient_plot(lm = TRUE)

ggsave("visuals/72hours-pct-neg-sent.png",
       width = 8, height = 4)


# TODO: Loop over each patient and perform a regression on their sentiment trajectory.



traj_df_summ = traj_df %>%
    dplyr::summarize(
      first72_neg_kw_sum = sum(num_neg_keywords),
      first72_pos_kw_sum = sum(num_pos_keywords),
      .groups = "keep"
    )
  
```

##  Aggregate data to patient-admission level

```{r agg_patient_admission}
# 45% death rate, although this includes replicates.
prop.table(table(data$expire_flag))

table(data$category)

head(data$los)

Mode <- function(x) {
  # Remove NAs
  ux <- setdiff(unique(x), NA)
  ux[which.max(tabulate(match(x, ux)))]
}

dim(data)

names(data)
summary(data$oasis_score)
qplot(data$oasis_score)
summary(data$oasis_prob)
# Highly correlated.
cor(data$oasis_prob, data$oasis_score)

dim(data)
# Only 7.7k patients.
length(unique(data$subject_id))

# Aggregate notes to the patient level and calculate various summary statistics.
# This takes 7 seconds on ssbvape.
system.time({
result = data %>% group_by(subject_id, hadm_id) %>%
  # Create a truncated version so that num_neg_keywords can be used in a denominator if it had been 0.
  mutate(num_neg_keywords_trunc = ifelse(num_neg_keywords == 0, 0.4, num_neg_keywords)) %>%
  summarize(# Adjustment variables.
            admission_type = first(admission_type),
            insurance = first(insurance),
            marital_status = first(marital_status),
            language = first(language),
            ethnicity = first(ethnicity),
            gender = first(gender),
            oasis_score = first(oasis_score),
            age1 = as.numeric(first(age)),
            #age2 = sort(table(as.numeric(age)), decreasing = TRUE)[1],
            age2 = as.numeric(Mode(age)),
            # Note category mixture.
            notes_consult = sum(category == "Consult"),
            notes_discharge = sum(category == "Discharge summary"),
            notes_general = sum(category == "General"),
            notes_nursing = sum(category == "Nursing"),
            notes_nutrition = sum(category == "Nutrition"),
            notes_physician = sum(category == "Physician"),
            notes_rehab = sum(category == "Rehab Services"),
            notes_respiratory = sum(category == "Respiratory"),
            notes_total = n(),
            # Outcomes
            los = first(length_of_stay),
            los2 = first(los2),
            los_days = first(los_days),
            expire_flag = first(expire_flag),
            # Life-sustaining therapies.
            # Mechanical ventilation, trach, dialysis, or pressor
            life_sustain = !is.na(mv_start_date) | !is.na(trach_start_date) |
              !is.na(dialysis_start_date) | !is.na(pressors_start_date),
            # Outcome components
            admittime = first(admittime),
            dischtime = first(dischtime),
            ################################
            # Sentiment measures
            mean_pos_keywords = mean(num_pos_keywords),
            # Excluding discharge summaries
            mean_pos_keywords_no_dis =
              mean(ifelse(cat == "Discharge",
                          NA,
                          num_pos_keywords),
                   na.rm = TRUE),
            median_pos_keywords = median(num_pos_keywords),
            mean_neg_keywords_no_dis = 
              mean(ifelse(cat == "Discharge",
                          NA,
                          num_neg_keywords),
                   na.rm = TRUE),
            median_neg_keywords = median(num_neg_keywords),
            median_pct_pos_keywords = median(num_pos_keywords / (num_pos_keywords + num_neg_keywords), na.rm = TRUE),
            # Excluding discharge summaries
            median_pct_pos_keywords_no_dis =
              median(ifelse(cat == "Discharge",
                            NA,
                            num_pos_keywords / (num_pos_keywords + num_neg_keywords)),
                     na.rm = TRUE),
            median_pct_neg_keywords = median(num_neg_keywords / (num_pos_keywords + num_neg_keywords), na.rm = TRUE),
            # Excluding discharge summaries
            median_pct_neg_keywords_no_dis =
              median(ifelse(cat == "Discharge",
                            NA,
                            num_neg_keywords / (num_pos_keywords + num_neg_keywords)),
                     na.rm = TRUE),
            mean_pct_pos_keywords = mean(num_pos_keywords / (num_pos_keywords + num_neg_keywords), na.rm  = TRUE),
            mean_sentiment_ratio = mean(num_pos_keywords / num_neg_keywords_trunc, na.rm = TRUE),
            # This one may not be working.
            median_sentiment_ratio = median(num_pos_keywords / num_neg_keywords_trunc, na.rm = TRUE),
            ###############
            # Benchmark sentiment measures
            median_deberta = median(sent_deberta, na.rm = TRUE),
            median_pattern = median(sent_pattern, na.rm = TRUE),
            median_stanza = median(sent_stanza, na.rm = TRUE),
            median_sentimentr = median(sent_sentimentr, na.rm = TRUE)
            ) %>%
  # Unclear why this extra step is needed. Did summarize() change, or did I mess something up?
  filter(row_number() == 1) %>% ungroup()
})

# 9.1k records.
dim(result)
```

## More processing

```{r more}

# 40k patients have only a single note, 3.5k have 2, and then there is a rare set of patients with 3 - 174 notes.
table(result$notes_total)
mean(result$notes_total == 1)
mean(result$notes_total == 2)
mean(result$notes_total > 2)

dim(result)

# 41,312 unique patients.
length(unique(result$subject_id))


str(result)
```

### Age

```{r age}
################


cor(result$age1, result$age2, use = "pairwise.complete.obs")
table("age1 missing" = is.na(result$age1), "age2 missing" = is.na(result$age2))

result$age = ifelse(!is.na(result$age1), result$age1, result$age2)

table(is.na(result$age))



# Impute age - no longer needed.
# result$missing_age = as.numeric(is.na(result$age))
# (median_age = median(result$age, na.rm = TRUE))
# result$age[result$missing_age == 1] = median_age
# table(is.na(result$age))

result$age1 = NULL
result$age2 = NULL
```

### Marital status

```{r marital}
# Make "single" be the reference level for marital status.
result$marital_status = forcats::fct_relevel(result$marital_status, "SINGLE") %>%
  forcats::fct_lump(prop = 0.02)
table(result$marital_status, useNA = "ifany")
prop.table(table(result$marital_status, useNA = "ifany"))
```

### Ethnicity

```{r ethnicity}
table(result$ethnicity)
prop.table(table(result$ethnicity))
result$ethnicity = forcats::fct_lump(result$ethnicity, prop = 0.02)
table(result$ethnicity)
```

### Language

```{r language}
table(result$language)
result$language = forcats::fct_lump(result$language, prop = 0.02)
table(result$language)
prop.table(table(result$language))
```


## Save dataset

```{r save_dataset}
save(result,
     file = "data/clean-keywords.RData")
```
