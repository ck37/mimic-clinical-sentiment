{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1602424774424,
     "user": {
      "displayName": "Chris Kennedy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiD_hpxe07s1ciHg3m-GksY10iiuhNWK9FAqpL_IntRUJH4IJTK2KROhyVoN6ngjs4-KERVCTDJcpZtiVs2ErG7qhUASKB8scusryurMLLDzZDXpQLxuH9-CCtpqQSQ1NBLp2H962Z7mjug3o_forRggl4VokvJCSCoVipyOrhTI5xWllPt3JHBM6gkV-tkyLMcfq0PZPPwNkKDs4ZBcC8NSn5rTDwQ-2LYJ6rVGagX_X35oPj8TxmR-Q3V2ltd-CGHsudc5joVscRnWg6aKJ4M-rXQ4OQMpPx_GbYaSreiDGEonZaS-ZJj9PxkjPAcHsJ_k8SoQixCVKeQcPbDHW7GSbmshoRBdWmcyvWbSVzhmgGccTDKwLdUfBrVSu0-QdboOKLLncEtLjclTrmO9413uPQbpiTdQ_kLd8FGuK-6MHyOv0fGcywY_F0dH4fMAbgOija0CZEGmnHo1KQ9BPyJREvHrWGrgSTFeISsr8tovTvzwMGyLPc49Gz88e9wRnAFm5lMdr3x4YkjT2KhP-AliAzqlpr0idEyyCbzlD8MsnUgbdRh600FQmWcEJzPJ8KgMXpO3rtkRzGGr0dxHjvzRKfp47ScSEZe3iQeCsvpQKafLvG7cTqcwXhy2cT5fkp-d6Hxr10oXgOOaR5UfW0XoF9gXbf4xcCdZHGrqmVjlrHNU0X-yoaGQXqd5HAr9YlM0IT1T6jnoK6hzyXnRLFk_UXZsWcvQUI1fcjd0x0vtgqBRE6-n8Bsloz-4rnddIDj9Q=s64",
      "userId": "05423414885832015580"
     },
     "user_tz": 240
    },
    "id": "rNqLIArs85P1",
    "outputId": "c8d395fb-a4fe-4818-8cc3-1aaafb1a9bdc"
   },
   "outputs": [],
   "source": [
    "import os, re, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(''~/ccBox/Research_Project/NLP/Master_Files/M006_all_pts_by_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tfidfscores_per_day_per_patient_no_dcsum_5.5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df65=df[df.AGE>=65]\n",
    "#df65.to_csv('~/ccBox/Research_Project/NLP/Master_Files/tfidfscores_per_day_per_65patient_4.20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percent_neg_words']=round(df.total_neg_words/(df.total_neg_words+df.total_pos_words), 2)\n",
    "df['percent_pos_words']=round(df.total_pos_words/(df.total_neg_words+df.total_pos_words), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique patients:', len(df.SUBJECT_ID.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_HD_start']=df.dialysis_start_date.map(lambda x: 0 if str(x)=='nan' else 1)\n",
    "df['num_dialysis_days']=df['num_dialysis_days'].fillna(0)\n",
    "df['HD_documented']=np.where((df.has_HD_start==1) | (df.num_dialysis_days>0), 1, 0)\n",
    "df['new_HD']=(df.days_until_dialysis.map(lambda x: int(''.join(re.findall(r'\\d', str(x)[0:6]))) if 'days' in str(x) else 0)>=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients on CRRT/HD:', len(df[df.has_HD_start==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation Number of patients on CRRT/HD:', len(df[df.HD_documented==True].SUBJECT_ID.unique()))\n",
    "print('New CRRT/HD:', len(df[df.new_HD==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation HD not on day of admission:', len(df[df.admit_date<df.dialysis_start_date].SUBJECT_ID.unique()))\n",
    "\n",
    "print('')\n",
    "HD_df=df[df.has_HD_start==True]\n",
    "print('HD_df shape', HD_df.shape)\n",
    "print('HD_df, new HD:', len(HD_df[HD_df.new_HD==True].SUBJECT_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Trach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_trach_start']=df.trach_start_date.map(lambda x: 0 if str(x)=='nan' else 1)\n",
    "df['num_trach_days']=df['num_trach_days'].fillna(0)\n",
    "df['trach_documented']=np.where((df.has_trach_start==1) | (df.num_trach_days>0), 1, 0)\n",
    "df['new_trach']=(df.days_until_trach.map(lambda x: int(''.join(re.findall(r'\\d', str(x)[0:6]))) if 'days' in str(x) else 0)>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients with Trach:', len(df[df.has_trach_start==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation Number of patients with Trach:', len(df[df.trach_documented==True].SUBJECT_ID.unique()))\n",
    "print('New Trach:', len(df[df.new_trach==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation New Trach:', len(df[df.admit_date<df.trach_start_date].SUBJECT_ID.unique()))\n",
    "\n",
    "\n",
    "print('')\n",
    "trach_df=df[df.has_trach_start==True]\n",
    "print('trach_df shape', trach_df.shape)\n",
    "print('trach_df, new trach:', len(trach_df[trach_df.new_trach==True].SUBJECT_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Pressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_pressors_start']=df.pressors_start_date.map(lambda x: 0 if str(x)=='nan' else 1)\n",
    "df['num_pressor_days']=df['num_pressor_days'].fillna(0)\n",
    "df['pressors_documented']=np.where((df.has_pressors_start==1) | (df.num_pressor_days>0), 1, 0)\n",
    "df['new_pressors']=(df.days_until_pressors.map(lambda x: int(''.join(re.findall(r'\\d', str(x)[0:6]))) if 'days' in str(x) else 0)>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients on pressors:', len(df[df.has_pressors_start==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation Number of patients on pressors:', len(df[df.pressors_documented==True].SUBJECT_ID.unique()))\n",
    "print('New Pressors started in ICU:', len(df[df.new_pressors==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation New Pressors:', len(df[df.admit_date<df.pressors_start_date].SUBJECT_ID.unique()))\n",
    "print('')\n",
    "pressors_df=df[df.has_pressors_start==True]\n",
    "print('pressors_df shape', pressors_df.shape)\n",
    "print('pressors_df, new pressors:', len(pressors_df[pressors_df.new_pressors==True].SUBJECT_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_mv_start']=df.mv_start_date.map(lambda x: 0 if str(x)=='nan' else 1)\n",
    "df['num_mv_days']=df['num_mv_days'].fillna(0)\n",
    "df['mv_documented']=np.where((df.has_mv_start==1) | (df.num_mv_days>0), 1, 0)\n",
    "df['new_mv']=(df.days_until_mechvent.map(lambda x: int(''.join(re.findall(r'\\d', str(x)[0:6]))) if 'days' in str(x) else 0)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients on MechVent:', len(df[df.has_mv_start==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation Number of patients on MechVent:', len(df[df.mv_documented==True].SUBJECT_ID.unique()))\n",
    "print('New MechVent:', len(df[df.new_mv==True].SUBJECT_ID.unique()))\n",
    "print('Confirmation New MechVent:', len(df[df.admit_date<df.mv_start_date].SUBJECT_ID.unique()))\n",
    "print('')\n",
    "MV_df=df[df.has_mv_start==True]\n",
    "print('MV_df shape', MV_df.shape)\n",
    "print('MV_df, new MechVent:', len(MV_df[MV_df.new_mv==True].SUBJECT_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language(string): \n",
    "    asian=['MAND', 'CANT', 'CAMB', 'VIET', 'HIND', 'LAOT', 'KORE', 'THAI', 'JAPA']\n",
    "    european=['GREE', 'RUSS', 'PORT', 'ITAL', 'POLI', 'FREN', 'TURK', 'GERM']\n",
    "    if string in asian: return 'East_Southeast_Asian'\n",
    "    elif string in european: return 'European_continental'\n",
    "    elif string=='ENGL': return 'English'\n",
    "    elif string=='SPAN': return 'Spanish'\n",
    "    else: return 'Other/Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language_summary']=df.LANGUAGE.map(lambda x: language(x))\n",
    "df['English']=np.where(df.language_summary=='English', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethnicity(string): \n",
    "    other=['UNABLE TO OBTAIN', 'UNKNOWN/NOT SPECIFIED', 'PATIENT DECLINED TO ANSWER', 'OTHER']\n",
    "    native=['AMERICAN INDIAN/ALASKA NATIVE', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE']\n",
    "    if 'ASIAN' in string: return 'Asian'\n",
    "    elif 'WHITE' in string: return 'White'\n",
    "    elif 'HISPANIC' in string: return 'Hispanic/Latino'\n",
    "    elif 'BLACK' in string: return 'Black'\n",
    "    elif string in native: return 'Native American or Hawaiian'\n",
    "    elif string in other: return 'Unknown/Declined'\n",
    "    else: return 'Multi/Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ethnicity_summary']=df.ETHNICITY.map(lambda x: ethnicity(x))\n",
    "df['White']=np.where(df.ethnicity_summary=='White', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LOS']=df.LENGTH_OF_STAY.map(lambda x: int(''.join(re.findall(r'\\d', str(x)[0:6]))) if 'days' in str(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note_day']=df.day_of_note_from_admit.map(lambda x: int(''.join(re.findall(r'(\\d+) days', x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick patch for AGE > 300 (should change in M001_merge)\n",
    "df['AGE']=df.AGE.map(lambda x: np.nan if x>=300 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elixhauser_categories']=df.prior_comorbidities.map(lambda x: x.split(','))\n",
    "pmh_dummies=pd.get_dummies(df.elixhauser_categories.apply(pd.Series).stack()).sum(level=0)\n",
    "pmh_dummies['total_comorbidities']=pmh_dummies.sum(axis=1)\n",
    "pmh_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_elix_pmh']=pmh_dummies['total_comorbidities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores=df.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['tfidf_score', 'percent_neg_words', 'percent_pos_words'].mean()\n",
    "avg_scores['avg_percent_neg_words']=avg_scores['percent_neg_words']\n",
    "avg_scores['avg_percent_pos_words']=avg_scores['percent_pos_words']\n",
    "avg_scores['avg_tfidf']=avg_scores['tfidf_score']\n",
    "avg_scores.drop(['tfidf_score', 'percent_neg_words', 'percent_pos_words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_by_day.HADM_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_day=df[['SUBJECT_ID', 'HADM_ID', 'CGID', 'AGE', 'GENDER', 'LOS', 'DC_TO_DEATH_HOSPICE', 'INSURANCE', \n",
    "       'language_summary', 'English', 'MARITAL_STATUS', 'ethnicity_summary', 'White', 'num_elix_pmh', 'OASIS_score', 'OASIS_prob', \n",
    "        'has_mv_start', 'has_HD_start', 'has_trach_start', 'has_pressors_start', 'note_day', 'tfidf_score', \n",
    "             'percent_neg_words', 'percent_pos_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge=pd.merge(df, avg_scores, on=['SUBJECT_ID', 'HADM_ID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_by_day=df_merge[['SUBJECT_ID', 'HADM_ID', 'CGID', 'AGE', 'GENDER', 'LOS', 'DC_TO_DEATH_HOSPICE', 'INSURANCE', \n",
    "#       'language_summary', 'English', 'MARITAL_STATUS', 'ethnicity_summary', 'White', 'num_elix_pmh', 'OASIS_score', 'OASIS_prob', \n",
    "#        'has_mv_start', 'has_HD_start', 'has_trach_start', 'has_pressors_start', 'avg_tfidf', 'avg_percent_neg_words', 'avg_percent_pos_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_day.to_csv('M006_all_pts_by_day.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df=df_by_day.drop_duplicates(subset=['SUBJECT_ID', 'HADM_ID'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv('M006_all_pts_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_df_65=summary_df[summary_df.AGE>=65]\n",
    "summ_df_65.to_csv('~/ccBox/Research_Project/NLP/Master_Files/M006_65_pts_avg.csv')\n",
    "\n",
    "summ_df_mv=summary_df[summary_df.has_mv_start==1]\n",
    "    summ_df_mv.to_csv('~/ccBox/Research_Project/NLP/Master_Files/M006_mv_pts_avg.csv')\n",
    "\n",
    "summ_df_mv65=summary_df[(summary_df.has_mv_start==1)&(summary_df.AGE>=65)]\n",
    "summ_df_mv65.to_csv('~/ccBox/Research_Project/NLP/Master_Files/M006_mv65_pts_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvLib6eAZojVgTuuMLAZ1a",
   "collapsed_sections": [],
   "name": "MIMIC Notes Demo-Chris.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
