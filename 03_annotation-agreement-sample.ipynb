{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation agreement sample\n",
    "\n",
    "This is run after 02_sentence-sentiment.ipynb.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1602424774424,
     "user": {
      "displayName": "Chris Kennedy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiD_hpxe07s1ciHg3m-GksY10iiuhNWK9FAqpL_IntRUJH4IJTK2KROhyVoN6ngjs4-KERVCTDJcpZtiVs2ErG7qhUASKB8scusryurMLLDzZDXpQLxuH9-CCtpqQSQ1NBLp2H962Z7mjug3o_forRggl4VokvJCSCoVipyOrhTI5xWllPt3JHBM6gkV-tkyLMcfq0PZPPwNkKDs4ZBcC8NSn5rTDwQ-2LYJ6rVGagX_X35oPj8TxmR-Q3V2ltd-CGHsudc5joVscRnWg6aKJ4M-rXQ4OQMpPx_GbYaSreiDGEonZaS-ZJj9PxkjPAcHsJ_k8SoQixCVKeQcPbDHW7GSbmshoRBdWmcyvWbSVzhmgGccTDKwLdUfBrVSu0-QdboOKLLncEtLjclTrmO9413uPQbpiTdQ_kLd8FGuK-6MHyOv0fGcywY_F0dH4fMAbgOija0CZEGmnHo1KQ9BPyJREvHrWGrgSTFeISsr8tovTvzwMGyLPc49Gz88e9wRnAFm5lMdr3x4YkjT2KhP-AliAzqlpr0idEyyCbzlD8MsnUgbdRh600FQmWcEJzPJ8KgMXpO3rtkRzGGr0dxHjvzRKfp47ScSEZe3iQeCsvpQKafLvG7cTqcwXhy2cT5fkp-d6Hxr10oXgOOaR5UfW0XoF9gXbf4xcCdZHGrqmVjlrHNU0X-yoaGQXqd5HAr9YlM0IT1T6jnoK6hzyXnRLFk_UXZsWcvQUI1fcjd0x0vtgqBRE6-n8Bsloz-4rnddIDj9Q=s64",
      "userId": "05423414885832015580"
     },
     "user_tz": 240
    },
    "id": "rNqLIArs85P1",
    "outputId": "c8d395fb-a4fe-4818-8cc3-1aaafb1a9bdc"
   },
   "outputs": [],
   "source": [
    "import os, re, time, sys\n",
    "import pandas as pd, numpy as np\n",
    "print(\"Python executable:\", sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created in 02_sentence-sentiment.ipynb\n",
    "sent_df = pd.read_feather(\"data/mimic-sentences-sentiment.feather\")\n",
    "\n",
    "print(sent_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to sentences with: chars >= 22, words >= 5, words <= 100\n",
    "# Need parentheses around each criterion.\n",
    "sent_df = sent_df.loc[(sent_df.chars >= 22) & (sent_df.words >= 5) & (sent_df.words <= 100)]\n",
    "\n",
    "# Down to 23 MM sentences.\n",
    "sent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to sentences with at least one keyword.\n",
    "kw_df = sent_df.loc[sent_df['keyword_count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 million sentences.\n",
    "print(kw_df.info())\n",
    "kw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df[['text', 'keywords', 'words', 'chars']].sample(20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df.keyword_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this really long one?\n",
    "kw_df.loc[kw_df.keyword_count == 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 100\n",
    "\"\"\"\n",
    "samp_df = kw_df.sample(100, random_state = 1)\n",
    "print(samp_df.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CK: disabled to avoid overwriting the sample that is already being used.\n",
    "\"\"\"\n",
    "samp_df.to_excel(\"data/annotation2-sample100.xlsx\", index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file then remove from df.\n",
    "samp_df = pd.read_excel(\"data/annotation2-sample100.xlsx\")\n",
    "samp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note which obs were in sample1.\n",
    "kw_df['sample'] = ''\n",
    "\n",
    "# Restrict just to the joining columns.\n",
    "join_df = samp_df[['row_id', 'sent_num']]\n",
    "join_df.set_index(['row_id', 'sent_num'], inplace = True)\n",
    "\n",
    "# Add a field to flag rows that match this sample.\n",
    "join_df['sample1'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df2 = kw_df.join(join_df, on = ['row_id', 'sent_num'], how = 'left')\n",
    "kw_df2['sample1'].value_counts()\n",
    "\n",
    "# Update the main sample column to track the sample 1 rows.\n",
    "kw_df2.loc[kw_df2['sample1'].values == True, 'sample'] = 'sample1'\n",
    "\n",
    "kw_df2['sample'].value_counts()\n",
    "\n",
    "# Confirm that shapes are still good.\n",
    "print(kw_df2.shape)\n",
    "print(kw_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 2 (2022-03-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 100\n",
    "samp_df2 = kw_df2.loc[kw_df2['sample'] == ''].sample(100, random_state = 1)\n",
    "print(samp_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CK: disabled to avoid overwriting the sample that is already being used.\n",
    "\"\"\"\n",
    "samp_df2.to_excel(\"data/annotation2-sample100-v2.xlsx\", index = False)\n",
    "samp_df2.to_csv(\"data/annotation2-sample100-v2.tsv\", sep = '\\t', index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file then tag in df.\n",
    "samp_df2 = pd.read_excel(\"data/annotation2-sample100-v2.xlsx\")\n",
    "samp_df2.info()\n",
    "\n",
    "# Restrict just to the joining columns.\n",
    "join_df = samp_df2[['row_id', 'sent_num']]\n",
    "join_df.set_index(['row_id', 'sent_num'], inplace = True)\n",
    "\n",
    "# Add a field to flag rows that match this sample.\n",
    "join_df['sample2'] = True\n",
    "\n",
    "kw_df3 = kw_df2.join(join_df, on = ['row_id', 'sent_num'], how = 'left')\n",
    "print(kw_df3['sample2'].value_counts())\n",
    "\n",
    "# Update the main sample column to track the sample 1 rows.\n",
    "kw_df3.loc[kw_df3['sample2'].values == True, 'sample'] = 'sample2'\n",
    "\n",
    "print(kw_df3['sample'].value_counts())\n",
    "\n",
    "# Confirm that shapes are still good.\n",
    "print(kw_df3.shape)\n",
    "print(kw_df2.shape)\n",
    "\n",
    "# Save df to disk for later usage.\n",
    "kw_df3.reset_index(drop = True).to_feather(\"data/annotation2-post-sample2.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 3 (2022-05-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-sample 2 file.\n",
    "kw_df3 = pd.read_feather(\"data/annotation2-post-sample2.feather\")\n",
    "# Review value counts.\n",
    "kw_df3['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 100 from the remaining sentences.\n",
    "samp_df3 = kw_df3.loc[kw_df3['sample'] == ''].sample(100, random_state = 1)\n",
    "print(samp_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CK: disabled to avoid overwriting the sample that is already being used.\n",
    "\"\"\"\n",
    "samp_df3.to_excel(\"data/annotation2-sample100-v3.xlsx\", index = False)\n",
    "sam_df3.to_csv(\"data/annotation2-sample100-v3.tsv\", sep = '\\t', index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file then tag in df.\n",
    "samp_df3 = pd.read_excel(\"data/annotation2-sample100-v3.xlsx\")\n",
    "samp_df3.info()\n",
    "\n",
    "# Restrict just to the joining columns.\n",
    "join_df = samp_df3[['row_id', 'sent_num']]\n",
    "join_df.set_index(['row_id', 'sent_num'], inplace = True)\n",
    "\n",
    "# Add a field to flag rows that match this sample.\n",
    "join_df['sample3'] = True\n",
    "\n",
    "kw_df4 = kw_df3.join(join_df, on = ['row_id', 'sent_num'], how = 'left')\n",
    "print(kw_df4['sample3'].value_counts())\n",
    "\n",
    "# Update the main sample column to track the sample 1 rows.\n",
    "kw_df4.loc[kw_df4['sample3'].values == True, 'sample'] = 'sample3'\n",
    "\n",
    "print(kw_df4['sample'].value_counts())\n",
    "\n",
    "# Confirm that shapes are still good.\n",
    "print(kw_df4.shape)\n",
    "print(kw_df3.shape)\n",
    "\n",
    "# Save df to disk for later usage.\n",
    "\"\"\"\n",
    "kw_df4.reset_index(drop = True).to_feather(\"data/annotation2-post-sample3.feather\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 4 (n = 750; 2022-07-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-sample 3 file.\n",
    "kw_df4 = pd.read_feather(\"data/annotation2-post-sample3.feather\")\n",
    "# Review value counts.\n",
    "kw_df4['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the sample in 4 steps:\n",
    "\n",
    "1. Score all excerpts with keyword sentiment.\n",
    "2. Among excerpts with keyword sentiment, create 5 quartile-based bins.\n",
    "3. Among excerpts with keyword sentiment, select 120 random excerpts per quartile (5 quartiles)\n",
    "4. Among excerpts without keyword sentiment, select 150 random excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Score keyword sentiment\n",
    "from clinsent import KeywordFinder\n",
    "\n",
    "kwf = KeywordFinder()\n",
    "text = 'bp is improving, but o2 worsening'\n",
    "hits, score = kwf.run(text)\n",
    "print(score)\n",
    "\n",
    "# This takes an hour+ with a single core.\n",
    "scores = []\n",
    "for excerpt in kw_df4.text.values:\n",
    "    # First result is hits\n",
    "    _, score = kwf.run(excerpt)\n",
    "    scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df4['kw_score'] = scores\n",
    "print(kw_df4['kw_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back on sentences without any keywords.\n",
    "# Restrict to sentences with at least one keyword.\n",
    "kw_df_no_kws = sent_df.loc[sent_df['keyword_count'] == 0]\n",
    "kw_df4_v2 = pd.concat([kw_df4, kw_df_no_kws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df4_v2['any_kw_score'] = (kw_df4_v2['kw_score'].notnull()).astype(int)\n",
    "# 2.5 MM excerpts with keywords.\n",
    "kw_df4_v2.any_kw_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quartile bins using https://pandas.pydata.org/docs/reference/api/pandas.qcut.html\n",
    "kw_df4 = kw_df4_v2\n",
    "kw_df4['kw_score_quartiles'] =  pd.cut(kw_df4.kw_score, 4)\n",
    "kw_df4.kw_score_quartiles.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by keyword sentiment score quartile.\n",
    "samp_df4_kws = kw_df4.loc[kw_df4['any_kw_score'] == 1].groupby('kw_score_quartiles').sample(150, random_state = 1)\n",
    "print(samp_df4_kws.shape)\n",
    "\n",
    "samp_df4_nokws = kw_df4.loc[kw_df4['any_kw_score'] == 0].sample(150, random_state = 1)\n",
    "\n",
    "# Combine the two samples\n",
    "samp_df4 = pd.concat([samp_df4_kws, samp_df4_nokws])\n",
    "print(samp_df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle row order.\n",
    "samp_df4 = samp_df4.sample(frac = 1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CK: disabled to avoid overwriting the sample that is already being used.\n",
    "samp_df4.to_excel(\"data/annotation2-sample750-v4.xlsx\", index = False)\n",
    "samp_df4.to_csv(\"data/annotation2-sample750-v4.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file then tag in df.\n",
    "samp_df4 = pd.read_excel(\"data/annotation2-sample750-v4.xlsx\")\n",
    "samp_df4.info()\n",
    "\n",
    "# Restrict just to the joining columns.\n",
    "join_df = samp_df4[['row_id', 'sent_num']]\n",
    "join_df.set_index(['row_id', 'sent_num'], inplace = True)\n",
    "\n",
    "# Add a field to flag rows that match this sample.\n",
    "join_df['sample4'] = True\n",
    "\n",
    "kw_df5 = kw_df4.join(join_df, on = ['row_id', 'sent_num'], how = 'left')\n",
    "print(kw_df5['sample4'].value_counts())\n",
    "\n",
    "# Update the main sample column to track the sample 1 rows.\n",
    "kw_df5.loc[kw_df4['sample4'].values == True, 'sample'] = 'sample4'\n",
    "\n",
    "print(kw_df5['sample'].value_counts())\n",
    "\n",
    "# Confirm that shapes are still good.\n",
    "print(kw_df5.shape)\n",
    "print(kw_df4.shape)\n",
    "\n",
    "# Save df to disk for later usage.\n",
    "kw_df5.reset_index(drop = True).to_feather(\"data/annotation2-post-sample4.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvLib6eAZojVgTuuMLAZ1a",
   "collapsed_sections": [],
   "name": "MIMIC Notes Demo-Chris.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
