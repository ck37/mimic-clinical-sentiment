{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1602424774424,
     "user": {
      "displayName": "Chris Kennedy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiD_hpxe07s1ciHg3m-GksY10iiuhNWK9FAqpL_IntRUJH4IJTK2KROhyVoN6ngjs4-KERVCTDJcpZtiVs2ErG7qhUASKB8scusryurMLLDzZDXpQLxuH9-CCtpqQSQ1NBLp2H962Z7mjug3o_forRggl4VokvJCSCoVipyOrhTI5xWllPt3JHBM6gkV-tkyLMcfq0PZPPwNkKDs4ZBcC8NSn5rTDwQ-2LYJ6rVGagX_X35oPj8TxmR-Q3V2ltd-CGHsudc5joVscRnWg6aKJ4M-rXQ4OQMpPx_GbYaSreiDGEonZaS-ZJj9PxkjPAcHsJ_k8SoQixCVKeQcPbDHW7GSbmshoRBdWmcyvWbSVzhmgGccTDKwLdUfBrVSu0-QdboOKLLncEtLjclTrmO9413uPQbpiTdQ_kLd8FGuK-6MHyOv0fGcywY_F0dH4fMAbgOija0CZEGmnHo1KQ9BPyJREvHrWGrgSTFeISsr8tovTvzwMGyLPc49Gz88e9wRnAFm5lMdr3x4YkjT2KhP-AliAzqlpr0idEyyCbzlD8MsnUgbdRh600FQmWcEJzPJ8KgMXpO3rtkRzGGr0dxHjvzRKfp47ScSEZe3iQeCsvpQKafLvG7cTqcwXhy2cT5fkp-d6Hxr10oXgOOaR5UfW0XoF9gXbf4xcCdZHGrqmVjlrHNU0X-yoaGQXqd5HAr9YlM0IT1T6jnoK6hzyXnRLFk_UXZsWcvQUI1fcjd0x0vtgqBRE6-n8Bsloz-4rnddIDj9Q=s64",
      "userId": "05423414885832015580"
     },
     "user_tz": 240
    },
    "id": "rNqLIArs85P1",
    "outputId": "c8d395fb-a4fe-4818-8cc3-1aaafb1a9bdc"
   },
   "outputs": [],
   "source": [
    "import os, re, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Created in MIMIC_004_keyword_prevalence-per_patient.ipynb\n",
    "#all_patients0 = pd.read_csv('data/keyword_prevalence_per_patient_nodummies_10.12.csv')\n",
    "all_patients0 = pd.read_csv('data/keyword_prevalence_per_patient_10.12.csv',\n",
    "                           low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_patients0.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_patients0.shape)\n",
    "all_patients=all_patients0[all_patients0.CATEGORY!='Discharge summary']\n",
    "print(all_patients.shape)\n",
    "# 7,667 patients as expected.\n",
    "print(\"Unique patients:\", all_patients.SUBJECT_ID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients['LENGTH_OF_STAY']=pd.to_timedelta(all_patients['LENGTH_OF_STAY'])\n",
    "all_patients['day_of_note_from_admit']=pd.to_datetime(all_patients['CHARTTIME']).dt.date-pd.to_datetime(all_patients['ADMITTIME']).dt.date\n",
    "all_patients['day_of_note_from_admit']=all_patients['day_of_note_from_admit'].fillna(all_patients['LENGTH_OF_STAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_patients[['ADMITTIME', 'DISCHTIME', 'CHARTTIME', 'CATEGORY', 'day_of_note_from_admit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of positive keywords is groupd by patient and day of note from admission\n",
    "all_patients.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])['NUM_POS_KEYWORDS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-determined keywords\n",
    "all_keywords=[]\n",
    "neg_keywords=pd.read_csv('data-raw/negative_keywords.csv').iloc[::,0]\n",
    "pos_keywords=pd.read_csv('data-raw/positive_keywords.csv').iloc[::,0]\n",
    "\n",
    "all_keywords.append(neg_keywords.apply(lambda x: x.strip()).tolist())\n",
    "all_keywords.append(pos_keywords.apply(lambda x: x.strip()).tolist())\n",
    "\n",
    "# Convert to a dictionary temporarily to deduplicate keyword list (\"concerning\" is duplicated)\n",
    "keywords= list(dict.fromkeys([i.lower() for i in all_keywords for i in i]))\n",
    "negative_keywords=[i.strip().lower() for i in neg_keywords]\n",
    "positive_keywords=[i.strip().lower() for i in pos_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total keywords:\", len(keywords))\n",
    "print(\", \".join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Takes 2 mins\n",
    "\n",
    "#finding Tfidf score per keyword \n",
    "#ngram_range=(1,2)\n",
    "#cv = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# We only need to count keywords, not all possible terms.\n",
    "cv = CountVectorizer(ngram_range = (1, 3), vocabulary = keywords)\n",
    "data = cv.fit_transform(all_patients.TEXT_SPLIT)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(data)\n",
    "\n",
    "# Extract the IDF scores to apply to term frequencies.\n",
    "word2tfidf = dict(zip(cv.get_feature_names(), tfidf_transformer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prints all the tfidf \"scores\" per keyword as dictionary\n",
    "print('Positive Keyword IDFs')\n",
    "positive_dictionary = {}\n",
    "for word, score in word2tfidf.items():\n",
    "    if word in positive_keywords: \n",
    "        x={word: score}\n",
    "        print(x)\n",
    "        positive_dictionary.update(x)\n",
    "\n",
    "print('')\n",
    "print('Negative Keyword IDFs')\n",
    "negative_dictionary = {}\n",
    "for word, score in word2tfidf.items():\n",
    "    if word in negative_keywords: \n",
    "        x={word: -1*score}\n",
    "        print(x)\n",
    "        negative_dictionary.update(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_patients['FOUND_STRING_KEYWORDS'].map(lambda x: x.replace('\\'','').replace('[','').replace(']',''))\n",
    "\"\"\"\n",
    "all_patients['FOUND_STRING_KEYWORDS']=all_patients.FOUND_KEYWORD_REPEATS.map(lambda x: ''.join(re.findall(r'\\'(\\w.+)\\'', x))) \n",
    "all_patients['FOUND_STRING_KEYWORDS_clean']=all_patients['FOUND_STRING_KEYWORDS'].map(lambda x: x.replace('\\'','').replace('[','').replace(']',''))\n",
    "all_patients['FOUND_STRING_KEYWORDS_clean'].head()\n",
    "dummies=all_patients['FOUND_STRING_KEYWORDS_clean'].str.get_dummies(sep=', ')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = all_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Takes 12 seconds.\n",
    "\n",
    "#Applies tfidf score to each keyword \n",
    "# CK: unclear what this chunk is trying to do vs. what would be ideal.\n",
    "#all_patients['FOUND_STRING_KEYWORDS']=all_patients.FOUND_KEYWORDS.map(lambda x: ''.join(re.findall(r'\\'(\\w.+)\\'', x))) \n",
    "\"\"\"\n",
    "all_patients['FOUND_STRING_KEYWORDS']=all_patients.FOUND_KEYWORD_REPEATS.map(lambda x: ''.join(re.findall(r'\\'(\\w.+)\\'', x))) \n",
    "all_patients['FOUND_STRING_KEYWORDS_clean']=all_patients['FOUND_STRING_KEYWORDS'].map(lambda x: x.replace('\\'','').replace('[','').replace(']',''))\n",
    "\n",
    "dummies=all_patients['FOUND_STRING_KEYWORDS_clean'].str.get_dummies(sep=', ')\n",
    "\"\"\"\n",
    "# positive keywords - only those found in the dataframe\n",
    "cols_to_update = list(set(positive_dictionary.keys()) & set(all_patients.columns))\n",
    "print(all_patients[cols_to_update].head())\n",
    "all_patients[cols_to_update] = all_patients[cols_to_update].astype('float64').mul(pd.Series(positive_dictionary), axis=1)[cols_to_update]\n",
    "print(all_patients[cols_to_update].head())\n",
    "\n",
    "# negative keywords - only those found in the dataframe.\n",
    "cols_to_update = list(set(negative_dictionary.keys()) & set(all_patients.columns))\n",
    "all_patients[cols_to_update] = all_patients[cols_to_update].astype('float64').mul(pd.Series(negative_dictionary), axis=1)[cols_to_update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kws = list(set(all_patients.columns) & set(positive_keywords + negative_keywords))\n",
    "print(all_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients['total_tfidf_score'] = all_patients[all_kws].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine demographics/outcomes and tfidf-scores \n",
    "#tfidf_df=pd.concat([all_patients, dummies], axis=1)\n",
    "tfidf_df = all_patients\n",
    "tfidf_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])['total_tfidf_score'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates concat_df, which groups total positive/negative words and tfidf score by day of admission \n",
    "num_pos_words = tfidf_df.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])['NUM_POS_KEYWORDS'].sum()\n",
    "num_neg_words = tfidf_df.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])['NUM_NEG_KEYWORDS'].sum()\n",
    "tfidf_score = tfidf_df.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])['total_tfidf_score'].mean()\n",
    "concat_df = pd.concat([num_pos_words, num_neg_words, tfidf_score], axis=1).reset_index()\n",
    "concat_df.columns=['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit', 'total_pos_words',\n",
    "                  'total_neg_words','tfidf_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_patients.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients['admit_date']=pd.to_datetime(all_patients['ADMITTIME']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_all_patients = all_patients[['SUBJECT_ID', 'HADM_ID', #'CATEGORY',\n",
    "                                 'admit_date', #'CGID', \n",
    "                                 'AGE', 'GENDER', 'EXPIRE_FLAG', 'DISCHARGE_LOCATION', 'INSURANCE', \n",
    "                                 'LANGUAGE', 'MARITAL_STATUS', 'ETHNICITY', 'DIAGNOSIS', \n",
    "                                 'num_mv_days', 'mv_start_date', 'mv_end_date', 'num_trach_days', 'trach_start_date', \n",
    "                                 'trach_end_date', 'num_dialysis_days', 'dialysis_start_date', 'dialysis_end_date', 'num_pressor_days', \n",
    "                                 'pressors_start_date', 'pressors_end_date', 'DC_TO_DEATH_HOSPICE', 'LENGTH_OF_STAY', 'days_until_mechvent', \n",
    "                                 'days_until_dialysis', 'days_until_pressors', 'days_until_trach', 'prior_comorbidities', 'OASIS_score', 'OASIS_prob']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_all_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trunc_all_patients2 = trunc_all_patients.groupby(['SUBJECT_ID', 'HADM_ID', 'day_of_note_from_admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging \n",
    "final_df = pd.merge(trunc_all_patients, concat_df, on = ['SUBJECT_ID', 'HADM_ID'], how='left')\n",
    "final_df['days_until_mechvent'] = pd.to_timedelta(final_df['days_until_mechvent'])\n",
    "final_df['days_until_dialysis'] = pd.to_timedelta(final_df['days_until_dialysis'])\n",
    "final_df['days_until_pressors'] = pd.to_timedelta(final_df['days_until_pressors'])\n",
    "final_df = final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.columns)\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sort_values(['SUBJECT_ID', 'HADM_ID']).iloc[0:25]#['SUBJECT_ID','HADM_ID','admit_date', 'AGE', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('data/tfidfscores_per_day_per_patient_no_dcsum_10.12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('tfidfscores_per_day_per_patient_4.20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves tfidf scores in csv \n",
    "csv_file = \"data/Negative_Keyword_Dictionary.csv\"\n",
    "with open(csv_file, 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in negative_dictionary.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves tfidf scores in csv \n",
    "csv_file = \"data/Positive_Keyword_Dictionary.csv\"\n",
    "with open(csv_file, 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in positive_dictionary.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvLib6eAZojVgTuuMLAZ1a",
   "collapsed_sections": [],
   "name": "MIMIC Notes Demo-Chris.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
